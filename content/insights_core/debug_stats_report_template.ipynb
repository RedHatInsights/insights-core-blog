{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "This is the \"debug_stats_report_template.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import importlib\n",
    "import sys\n",
    "import inspect\n",
    "from collections import defaultdict\n",
    "from IPython.core.display import display, HTML\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import shlex\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "log= logging.getLogger( __name__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set Pandas to display dataframe w/o truncation\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parse_cmd_args(nb_args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--plugin_analyzer_output \", dest='plugin_analyzer_output', type=str)\n",
    "    parser.add_argument(\"--ex_lib_path\", dest='ex_lib_path', type=str, default=\"\")\n",
    "    parser.add_argument(\"--ex_libs\", dest='ex_libs', nargs='+', type=str, default=\"\")    \n",
    "    return parser.parse_args(shlex.split(nb_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# HideMe\n",
    "# Input arguments\n",
    "nb_args = os.environ.get('NB_ARGS', \"\")\n",
    "log.info(\"nb_args = %s\", nb_args)\n",
    "\n",
    "if not nb_args:\n",
    "    nb_args = \"\"\"\n",
    "--plugin_analyzer_output /1 \n",
    "--ex_lib_path /1/libs \n",
    "--ex_libs   insights_analysis_stats.egg\n",
    "            insights_core-1.45.0-py2.7.egg\n",
    "            insights_plugins-1.43.0-py2.7.egg\n",
    "            Jinja2-2.9.6-py2.7.egg\n",
    "            MarkupSafe-1.0-py2.7-linux-x86_64.egg\n",
    "            PyYAML-3.12-py2.7.egg \n",
    "    \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ReplaceString=@nb_args\n",
    "# nb_args = \"@nb_args\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Common func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_pd_df_json(json_file):\n",
    "    if not os.path.exists(json_file):\n",
    "        raise ValueError(\"there is no file at %s\" % json_file)\n",
    "    return pd.read_json(json_file, lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def display_no_index(df):\n",
    "    display(HTML(df.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_highlight(text, high_lights = []):    \n",
    "    for high_light in high_lights:\n",
    "        text = text.replace(high_light, \"<mark>%s</mark>\" % high_light)\n",
    "        \n",
    "    display(HTML('<div class=\"output_subarea output_stream output_stdout output_text\"><pre>%s</pre></div' % text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# I. Stat App Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "args = parse_cmd_args(nb_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(ex_lib_path='/1/libs', ex_libs=['insights_analysis_stats.egg', 'insights_core-1.45.0-py2.7.egg', 'insights_plugins-1.43.0-py2.7.egg', 'Jinja2-2.9.6-py2.7.egg', 'MarkupSafe-1.0-py2.7-linux-x86_64.egg', 'PyYAML-3.12-py2.7.egg'], plugin_analyzer_output='/1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'spark' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0d7ebf552ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddPyFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0madd_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mex_lib_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mex_libs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-0d7ebf552ad0>\u001b[0m in \u001b[0;36madd_lib\u001b[0;34m(lib_dir, lib_files)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"add file to classpath = %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddPyFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0madd_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mex_lib_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mex_libs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'spark' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# set up libs\n",
    "def add_lib(lib_dir, lib_files = []):\n",
    "    libs=[]\n",
    "    for f in lib_files:\n",
    "        p = os.path.join(lib_dir, f)            \n",
    "        sys.path.append(p)   \n",
    "        log.info(\"add file to classpath = %s\", p)        \n",
    "        spark.sparkContext.addPyFile(p)\n",
    "    \n",
    "add_lib(args.ex_lib_path, args.ex_libs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# archive location\n",
    "#Convert=code\n",
    "stat_data_dir = args.plugin_analyzer_output\n",
    "if not os.path.exists(stat_data_dir):\n",
    "    raise ValueError(\"there is no directory at %s\" % stat_data_dir)\n",
    "    \n",
    "print \"stat_data_dir = '%s'\" % args.plugin_analyzer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.read.parquet(\"file:%s\" % os.path.join(args.plugin_analyzer_output, 'data/rule_analysis')).registerTempTable(\"ra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# HideMe\n",
    "nb_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rm = read_pd_df_json(os.path.join(args.plugin_analyzer_output, 'data/rule_meta.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# HideMe\n",
    "rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rule_module = str(rm['input_rule_pkgs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# HideMe\n",
    "rule_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "importlib.import_module(rule_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Archive Sync Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"Archive Sync time = %s\" % sql(\"\"\"select max(upload_time) as mut from ra\"\"\").collect()[0]['mut']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# show the schema of report analysis data\n",
    "\n",
    "# system_id       : is a system identificiation. A system usually upload an archive to us once a day\n",
    "# stats_upload_id : is an archive id, so if a system upload 2 archives, we will have 1 system_id and 2 stats_upload_id\n",
    "\n",
    "# type      : is component type: rule/condition/incident\n",
    "# name      : your function name for the annotated rule/condition/incident\n",
    "# value     : is a json value of your function output. If the output is not jsonable, it will be \"unjsonable\"\n",
    "# is_fire   : indicate the result of bool(your_function_output)\n",
    "# error_key : error key generate from rule response\n",
    "\n",
    "# upload_time : is the time the archive uploaded to s3\n",
    "\n",
    "sql(\"\"\"select * from ra\"\"\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Viewing components of your rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Show all the name of your condition/indicent/rule method names\n",
    "sql(\"\"\"select type, name, count(0) as count from ra group by name, type\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. Collect sample problem archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_exception_samples(exception_df):\n",
    "    samples = defaultdict(list)\n",
    "    exception_types = set()\n",
    "    for index, row in exception_df.iterrows():\n",
    "        d = row.to_dict() \n",
    "        system_id = d['system_id']\n",
    "        del d['system_id']\n",
    "        et = json.dumps(d)\n",
    "        samples[et].append(system_id)\n",
    "    \n",
    "    return [{'sample_type': 'exception', 'desc': key, 'count': len(value), 'system_ids': \",\".join(value)} for key, value in samples.iteritems()]\n",
    "\n",
    "    \n",
    "def get_sample_archives_df(stat_data_dir):        \n",
    "    \n",
    "    base_archive_dir = os.path.join(stat_data_dir, 'data')        \n",
    "    sample_archives = []\n",
    "    for root, directories, filenames in os.walk(base_archive_dir):    \n",
    "        for filename in filenames:\n",
    "            if filename.endswith(\"_df.json\"):\n",
    "                full_path = os.path.join(root,filename)\n",
    "                sample_type = filename.split(\"_df.json\")[0]\n",
    "                df = read_pd_df_json(full_path)\n",
    "                if df.empty:                    \n",
    "                    continue\n",
    "                    \n",
    "                if 'exception' == sample_type:\n",
    "                    sample_archives.extend(get_exception_samples(df))  \n",
    "                    \n",
    "    sample_archives_df = pd.DataFrame(sample_archives)\n",
    "    # rearrange column order\n",
    "    sample_archives_df = sample_archives_df[['sample_type', 'count', 'desc', 'system_ids']]\n",
    "    \n",
    "    return sample_archives_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_archives_df = get_sample_archives_df(stat_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_archives_df[['sample_type', 'count', 'desc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# II. Analyze Stat Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_rule_components(rule_module, component_type):\n",
    "    \"\"\"\n",
    "    Return parsers with the component_type for your rule.\n",
    "    component_type can be either incident/parser/rule \n",
    "    \"\"\"\n",
    "    rule_reducer = plugins.REDUCERS[rule_module.split(\".\")[-1]]\n",
    "    components = plugins.COMPONENTS_BY_TYPE[component_type]\n",
    "    \n",
    "    parsers = set()\n",
    "    for dep in plugins.COMPONENT_DEPENDENCIES[rule_reducer]:\n",
    "        if dep in components:\n",
    "            for parser in plugins.COMPONENT_DEPENDENCIES[dep]:\n",
    "                parsers.add(parser)\n",
    "    return parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_system_id_from_archive_path(path):\n",
    "    return path.split(\"/\")[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_spec_files(archives, spec_name, high_lights = [], filter_high_lights=False):\n",
    "    \"\"\"\n",
    "    print the content of a file based on its spec_name\n",
    "    :param archives list of archives to view\n",
    "    :param spec_name parser spec name\n",
    "    :param high_lights: list of string to high light\n",
    "    :param filter_high_lights: only show string match one of the high_lights\n",
    "    :return: None. this will just print to screen directly\n",
    "    \"\"\"\n",
    "    for archive in archives:\n",
    "        with TarExtractor().from_path(archive, extract_dir=tmp_extract_dir) as ex:\n",
    "            spec_mapper = SpecMapper(ex)        \n",
    "            if not spec_mapper.exists(spec_name):\n",
    "                print \"There is no file corresponding to spec_name = %s\" % spec_name\n",
    "\n",
    "            if filter_high_lights:\n",
    "                lines = spec_mapper.get_content(path=spec_name, split=True)\n",
    "                filtered_lines = []\n",
    "                for l in lines:\n",
    "                    for h in high_lights:\n",
    "                        if h in l:\n",
    "                            filtered_lines.append(l)\n",
    "                            break\n",
    "                content = \"\\n\".join(filtered_lines)\n",
    "            else:\n",
    "                content = spec_mapper.get_content(path=spec_name, split=False)\n",
    "\n",
    "            if content:\n",
    "\n",
    "                print \"==============================================================================================\"\n",
    "                print \"==== spec : %s, system_id = %s\" % (spec_name, get_system_id_from_archive_path(archive))\n",
    "                #print \"==== The highlights are the parser filters\"\n",
    "                print \"==============================================================================================\"            \n",
    "                print_highlight(content, high_lights)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Viewing Parser Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from insights.core.archives import TarExtractor\n",
    "from insights.core.specs import SpecMapper\n",
    "from insights.core import plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_incident_parser_content(archive, rule_module):\n",
    "    incident_parsers = get_rule_components(rule_module, plugins.incident)    \n",
    "    if not incident_parsers:\n",
    "        print \"there is no incident parser\"\n",
    "    \n",
    "    for parser in incident_parsers:\n",
    "        for name in parser.symbolic_names:\n",
    "            content = print_spec_files([archive], name, parser.filters)\n",
    "            if content:\n",
    "                break   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Select a sample archive in here. There is a convience method **`print_incident_parser_content`** to view incident parser content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_archive_file_paths(sample_archives_df, index):\n",
    "    system_ids = sample_archives_df.iloc[[0]]['system_ids'][0].split(\",\")\n",
    "    return [os.path.join(stat_data_dir, 'data/samples/archives/%s.tar.gz' % sid) for sid in system_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tmp_extract_dir='/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_archive = None\n",
    "if not sample_archives_df.empty:        \n",
    "    sample_archive = get_archive_file_paths(sample_archives_df, 0)[0]    \n",
    "    \n",
    "    sample_type = sample_archives_df.iloc[[0]]['sample_type'][0]\n",
    "    \n",
    "    if 'misdiagnose' == sample_type:\n",
    "        print_incident_parser_content(sample_archive, rule_module)\n",
    "    elif 'exception' == sample_type:\n",
    "        # just view any spec that you want to investigate, choosing uname because it is the most common one\n",
    "        # for example, we want to high light 'x86' and 'Linux'\n",
    "        n = print_spec_files([sample_archive], 'uname', high_lights=['x86', 'Linux'], filter_high_lights=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* You can view other spec file like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if sample_archive:\n",
    "    # print with text high light\n",
    "    print_spec_files([sample_archive], 'uname', high_lights=['x86', 'Linux'], filter_high_lights=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* You can view spec from multiple archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# print all file of spec name\n",
    "print_spec_files(get_archive_file_paths(sample_archives_df, 0), 'uname')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Viewing Rule Component Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if sample_archive:    \n",
    "    system_id = get_system_id_from_archive_path(sample_archive)     \n",
    "    display_no_index(sql(\"\"\"\n",
    "    select rhel_major_ver as rhel, type, name, is_fire, value \n",
    "    from ra where system_id = '%s'\"\"\" % system_id).toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# III. Modify your rule and test it with sample archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clear_reducer():\n",
    "    for p in plugins.SHARED_PARSERS:\n",
    "        if hasattr(p, 'filters') and p.filters:\n",
    "            p.filters = []\n",
    "        \n",
    "    \"\"\"\n",
    "    clear out your previous reducer, otherwise it will be computed together with your new reducer\n",
    "    which makes it harder to see the result\n",
    "    \"\"\"    \n",
    "    for m in [plugins.TYPE_OF_COMPONENT, plugins.COMPONENTS_BY_TYPE, \n",
    "              plugins.COMPONENT_DEPENDENCIES, plugins.EMITTERS,\n",
    "              plugins.DELEGATES, plugins.REDUCERS, plugins.PARSERS, \n",
    "              plugins.PARSER_FUNCS]:\n",
    "        m.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Assign plugin_src\n",
    "#Convert=code\n",
    "src =inspect.getsource(module) \n",
    "src = \"\"\"\n",
    "# Clearning up reducer so your previous reducer doesn't compute again\\nclear_reducer()\n",
    "#===================Your code start from here===================\n",
    "\n",
    "%s\"\"\" % src\n",
    "exec(src)\n",
    "print src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ReplaceString=@rule_code\n",
    "# Clearning up reducer so your previous reducer doesn't compute again\n",
    "clear_reducer()\n",
    "#===================Your code start from here===================\n",
    "\n",
    "\"@rule_code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reducer_func=plugins.REDUCERS['__main__']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from insights_analysis_stats.core.evaluator.stats_evaluator import StatsSingleEvaluator, get_register_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Execute your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if sample_archive:\n",
    "    with TarExtractor().from_path(sample_archive, extract_dir=tmp_extract_dir) as ex:\n",
    "        system_id = get_system_id_from_archive_path(sample_archive)\n",
    "        registered_components = get_register_components(reducer_func.__module__, [plugins.rule, plugins.condition, plugins.incident])    \n",
    "        spec_mapper = SpecMapper(ex)\n",
    "        p = StatsSingleEvaluator(spec_mapper)\n",
    "        evaluator_response = p.process()\n",
    "        print \"=================================\"\n",
    "        print \"==== evaluator response\"\n",
    "        print \"=================================\"    \n",
    "        print evaluator_response\n",
    "        print \"\"\n",
    "        print \"=================================\"\n",
    "        print \"==== stats response\"\n",
    "        print \"=================================\"    \n",
    "\n",
    "        stats_response = p.get_rule_outputs(stats_upload_id=system_id, module_name=rule_module, registered_components=registered_components)    \n",
    "        display_no_index(pd.DataFrame(stats_response).drop(['stats_upload_id', 'module'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
